{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* project_deliverable_3.ipynb\n",
    "#*\n",
    "#* ANLY 555 2023\n",
    "#* Project <>\n",
    "#*\n",
    "#* Due on: 10/25/2023\n",
    "#* Author(s): Landon Carpenter\n",
    "#*\n",
    "#*\n",
    "#* In accordance with the class policies and Georgetown's\n",
    "#* Honor Code, I certify that, with the exception of the\n",
    "#* class resources and those items noted below, I have neither\n",
    "#* given nor received any assistance on this project other than\n",
    "#* the TAs, professor, textbook and teammates.\n",
    "#*\n",
    "\n",
    "import csv\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import wordcloud as wordcloud\n",
    "\n",
    "#create dataset class\n",
    "class DataSet:\n",
    "    \"\"\"\n",
    "    Class for managing the dataset\n",
    "    \n",
    "    Attribute:\n",
    "        filename (str): the name of the file to be read in\n",
    "    \"\"\"\n",
    "\n",
    "    #constructor\n",
    "    def __init__(self, filename, ):\n",
    "        \"\"\"\n",
    "        Initializes the DataSet class\n",
    "        \"\"\"\n",
    "        self.filename = filename\n",
    "        self.data = None\n",
    "\n",
    "    #create the framework and stubs for __readFromCSV, __load, clean, and explore\n",
    "    def __readFromCSV(self, filename, header = True):\n",
    "        \"\"\"\n",
    "        Reads in the data from a CSV file. The data is stored on a column basis similar to a parquet file to more easily account for data types.\n",
    "\n",
    "        Args:\n",
    "            filename (str): the name of the file to be read in\n",
    "            header (bool): whether or not the file has a header\n",
    "\n",
    "        Returns:\n",
    "            data (np.array): the data read in from the CSV file\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(filename, 'r', encoding='utf-8') as f:\n",
    "                reader = csv.reader(f)\n",
    "                data = list(reader)\n",
    "\n",
    "                if header:\n",
    "                    header = data[0]\n",
    "                    data = data[1:]\n",
    "                else:\n",
    "                    header = [f\"col_{i}\" for i in range(len(data[0]))]\n",
    "\n",
    "                #init the dict to store the data\n",
    "                columns = {col_name: [] for col_name in header}\n",
    "\n",
    "                for row in data:\n",
    "                    for col_name, value in zip(header, row):\n",
    "                        try:\n",
    "                            columns[col_name].append(float(value))\n",
    "                        except:\n",
    "                            columns[col_name].append(value)\n",
    "                            #if the value is '' then replace it with np.nan\n",
    "                            if value == '':\n",
    "                                columns[col_name][-1] = np.nan\n",
    "                            else:\n",
    "                                pass\n",
    "\n",
    "\n",
    "                #ok now convert to numpy array\n",
    "                d_type = [(col_name, object if any(isinstance(val, str) for val in columns[col_name]) else float) for col_name in header]\n",
    "                self.data = np.array(list(zip(*[columns[col_name] for col_name in header])), dtype = d_type)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename}: {str(e)}\")\n",
    "\n",
    "        return self.data\n",
    "\n",
    "                    \n",
    "                        \n",
    "\n",
    "\n",
    "\n",
    "    #abstract base class (ABC)\n",
    "    def __load(self, filename):\n",
    "        \"\"\"\n",
    "        Loads the data from a CSV file and also calls the getType and readFromCSV functions\n",
    "\n",
    "        Args:\n",
    "            filename (str): the name of the file to be read in\n",
    "\n",
    "        Returns:\n",
    "            data (np.array): the data read in from the CSV file\n",
    "        \"\"\"\n",
    "        print(f\"Loading {filename}...\")\n",
    "\n",
    "        #get the type of data\n",
    "        data_type = self.getType()\n",
    "\n",
    "        #if the data is time series set header to false\n",
    "        if data_type == 'time':\n",
    "            header = False\n",
    "        else:\n",
    "            header = True\n",
    "\n",
    "        self.__readFromCSV(filename, header=header)\n",
    "\n",
    "        return self.data\n",
    "\n",
    "\n",
    "    def getType(self):\n",
    "        \"\"\"\n",
    "        This function will be called later in each of the child classes to determine the type of data\n",
    "\n",
    "        Returns:\n",
    "            data_type (str): the type of data\n",
    "        \"\"\"\n",
    "\n",
    "        #using while True to avoid infinite loop that I had earlier\n",
    "        while True:\n",
    "            data_type = input(\"Is this data Time Series, Text, Quantitative, or Qualitative? \\nPlease type 'Time', 'Text', 'Quantitative', or 'Qualitative'.\")\n",
    "            #trying to make the prompt a little more forgiving by making the input lowercase and removing whitespace before checking for validity\n",
    "            norm = data_type.lower().strip()\n",
    "\n",
    "            #make sure the type is valid\n",
    "            if norm in ['time', 'text', 'quantitative', 'qualitative']:\n",
    "                return norm\n",
    "\n",
    "            #if the type is not valid they will see this message and be prompted to try again\n",
    "            else:\n",
    "                print(\"Please enter a valid data type.\")\n",
    "\n",
    "\n",
    "    def clean(self):\n",
    "        \"\"\"\n",
    "        Cleans the data\n",
    "        \"\"\"\n",
    "        print(\"Cleaning...\")\n",
    "\n",
    "    def explore(self):\n",
    "        \"\"\"\n",
    "        Explores the data\n",
    "        \"\"\"\n",
    "        print(\"Exploring...\")\n",
    "        \n",
    "\n",
    "#use inheritance to create TimeSeriesDataSet class\n",
    "class TimeSeriesDataSet(DataSet):\n",
    "    \"\"\"\n",
    "    Class for managing the time series dataset. Uses a median filter to clean the data. The data used in the test is mitbih_trian.csv\n",
    "\n",
    "    Attribute:\n",
    "        filename (str): the name of the file to be read in\n",
    "    \"\"\"\n",
    "\n",
    "    #constructor\n",
    "    def __init__(self, filename):\n",
    "        \"\"\"\n",
    "        Initializes the TimeSeriesDataSet class\n",
    "        \"\"\"\n",
    "        super().__init__(filename)\n",
    "        self.filename = filename\n",
    "        self.data = self._DataSet__load(filename)\n",
    "\n",
    "    #override the clean and explore methods from the DataSet class to be specific to the TimeSeriesDataSet class\n",
    "    def clean(self, filter_size = (3, 3)):\n",
    "        \"\"\"\n",
    "        Cleans the time series data set using a median filter\n",
    "\n",
    "        Args:\n",
    "            filter_size (tuple): the size of the filter to use\n",
    "\n",
    "        Returns:\n",
    "            filtered_data (np.array): the filtered data\n",
    "        \"\"\"\n",
    "        print(\"Cleaning Time Series Data Set...\")\n",
    "\n",
    "        #get the stored data that was read in \n",
    "        data = self.data\n",
    "\n",
    "        names = self.data.dtype.names\n",
    "\n",
    "        arr = []\n",
    "\n",
    "        for row in data:\n",
    "            row_arr = []\n",
    "            for name in names:\n",
    "                row_arr.append(row[name])\n",
    "\n",
    "            arr.append(row_arr)\n",
    "        arr = np.array(arr)\n",
    "\n",
    "        pad = (filter_size[0] // 2, filter_size[1] // 2)\n",
    "        print(f\"padding: {pad}\")\n",
    "        rows, cols = arr.shape\n",
    "        print(f\"rows: {rows}, cols: {cols}\")\n",
    "\n",
    "        #to store the filtered data\n",
    "        filtered_data = np.zeros((rows, cols))\n",
    "\n",
    "        for i in range(rows):\n",
    "            start, end = i - pad[0], i + pad[0] + 1\n",
    "\n",
    "            #apply median filter over the row\n",
    "            filtered_data[i] = np.median(arr[max(start, 0):min(end, rows)], axis = 0)\n",
    "\n",
    "        self.data = filtered_data\n",
    "\n",
    "\n",
    "    def explore(self):\n",
    "        \"\"\"\n",
    "        Explores the time series data set by creating at least two visualizations. creates a scatter plot and a line plot.and a saves it to the path that is declared in the function (to visualizations folder). Additionally the user has the option of specifying a title, x-axis label, and y-axis label for the plot.\n",
    "        \"\"\"\n",
    "        print(\"Exploring Time Series Data Set...\")\n",
    "\n",
    "        #ask the user if they want to specify title, x-axis label, and y-axis label or use defaults\n",
    "        custom = input(\"Would you like to specify the title, x-axis label, and y-axis label? \\nPlease type 'Yes' or 'No'.\")\n",
    "        if custom == 'Yes':\n",
    "            #get input to ask for the Title, X-axis label, and Y-axis label\n",
    "            title = input(\"Please enter a title for the plot: \")\n",
    "            x_label = input(\"Please enter a label for the x-axis: \")\n",
    "            y_label = input(\"Please enter a label for the y-axis: \")\n",
    "        else:\n",
    "            #set the title, x-axis label, and y-axis label to default values\n",
    "            title = \"ECG Time Series Data\"\n",
    "            x_label = \"Time\"\n",
    "            y_label = \"Heartbeat\"\n",
    "        \n",
    "        #create a path to save the plot\n",
    "        path = 'visualizations/ECG_Time_Series_Scatter.png'\n",
    "        #set the figure size\n",
    "        plt.figure(figsize=(10, 5))\n",
    "\n",
    "        #ask for a row to explore\n",
    "        row = int(input(\"Please enter a ID (row) to explore: \"))\n",
    "\n",
    "        #create a scatter plot, I genuinly need this one because I'm still unsure what is going on with this data. \n",
    "        #create a scatter plot of the row that was input which would likely be the patients ecg over the give time period (columns)\n",
    "        plt.scatter(range(len(self.data[row])), self.data[row])\n",
    "\n",
    "        #set the title, x-axis label, and y-axis label\n",
    "        plt.title(title)\n",
    "        plt.xlabel(x_label)\n",
    "        plt.ylabel(y_label)\n",
    "\n",
    "        #save the plot\n",
    "        plt.savefig(path)\n",
    "        #close the plot\n",
    "        plt.close()\n",
    "\n",
    "        # #show the plot\n",
    "        # plt.show()\n",
    "\n",
    "        path = 'visualizations/ECG_Time_Series_Line.png'\n",
    "        plt.figure(figsize=(10, 5))\n",
    "\n",
    "        #now create a line plot to show the distribution of the data with less noise\n",
    "        plt.plot(range(len(self.data[row])), self.data[row])\n",
    "\n",
    "        #set the title, x-axis label, and y-axis label\n",
    "        plt.title(title)\n",
    "        plt.xlabel(x_label)\n",
    "        plt.ylabel(y_label)\n",
    "\n",
    "        #save the plot\n",
    "        plt.savefig(path)\n",
    "        #close the plot\n",
    "        plt.close()\n",
    "\n",
    "        # #show the plot\n",
    "        # plt.show()\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "class TextDataSet(DataSet):\n",
    "    \"\"\"\n",
    "    Class for managing the text dataset. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        \"\"\"\n",
    "        Initializes the TextDataSet class\n",
    "        \"\"\"\n",
    "        super().__init__(filename)\n",
    "        self.filename = filename\n",
    "        self.data = self._DataSet__load(filename)\n",
    "\n",
    "    def clean(self):\n",
    "        \"\"\"\n",
    "        Cleans the text data set. Removes stop words and lemmatizes the data.\n",
    "\n",
    "        Returns:\n",
    "            cleaned_data (np.array): the cleaned data\n",
    "        \"\"\"\n",
    "        print(\"Cleaning Text Data Set...\")\n",
    "\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "\n",
    "        #if the column is a string then remove stop words\n",
    "        for col in self.data.dtype.names:\n",
    "            if col == 'text':\n",
    "                col_data = self.data[col]\n",
    "\n",
    "                for i in range(len(col_data)):\n",
    "                    word_tokens = nltk.word_tokenize(col_data[i])\n",
    "\n",
    "                    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "\n",
    "                    filtered_sentence = []\n",
    "\n",
    "                    for w in word_tokens:\n",
    "                        if w not in stop_words:\n",
    "                            filtered_sentence.append(w)\n",
    "\n",
    "                    col_data[i] = filtered_sentence\n",
    "\n",
    "                self.data[col] = col_data\n",
    "\n",
    "        #lemmatize the data\n",
    "        for col in self.data.dtype.names:\n",
    "            if col == 'text':\n",
    "                col_data = self.data[col]\n",
    "\n",
    "                for i in range(len(col_data)):\n",
    "                    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "                    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in col_data[i]])\n",
    "                    col_data[i] = lemmatized_output\n",
    "\n",
    "                self.data[col] = col_data\n",
    "\n",
    "    def explore(self):\n",
    "        \"\"\"\n",
    "        Explores the text data set. Creates a word cloud and a histogram of the star ratings. The user has the option of specifying a title, x-axis label, and y-axis label for the plot.\n",
    "        \"\"\"\n",
    "        print(\"Exploring Text Data Set...\")\n",
    "\n",
    "        #ask the user if they want to specify title, x-axis label, and y-axis label or use defaults\n",
    "        custom = input(\"Would you like to specify the title, x-axis label, and y-axis label for the word cloud? \\nPlease type 'Yes' or 'No'.\")\n",
    "        if custom == 'Yes':\n",
    "            #get input to ask for the Title, X-axis label, and Y-axis label\n",
    "            title = input(\"Please enter a title for the plot: \")\n",
    "            x_label = input(\"Please enter a label for the x-axis: \")\n",
    "            y_label = input(\"Please enter a label for the y-axis: \")\n",
    "\n",
    "        else:\n",
    "            #set the title, x-axis label, and y-axis label to default values\n",
    "            title = \"Word Cloud\"\n",
    "            x_label = \"\"\n",
    "            y_label = \"\"\n",
    "\n",
    "\n",
    "        path = 'visualizations/word_cloud.png'\n",
    "        #create a word cloud from the top 100 words\n",
    "        cloud = wordcloud.WordCloud().generate(self.data['text'][0])\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(title)\n",
    "        plt.xlabel(x_label)\n",
    "        plt.ylabel(y_label)\n",
    "        plt.imshow(cloud)\n",
    "\n",
    "        #save the plot\n",
    "        plt.savefig(path)\n",
    "\n",
    "        #close the plot\n",
    "        plt.close()\n",
    "\n",
    "        # plt.show()\n",
    "\n",
    "        path = 'visualizations/star_ratings.png'\n",
    "        plt.figure(figsize=(10, 5))\n",
    "\n",
    "        #send self.data['stars'] to ints for histogram\n",
    "        self.data['stars'] = self.data['stars'].astype(int)\n",
    "\n",
    "        custom = input(\"Would you like to specify the title, x-axis label, and y-axis label for the histogram? \\nPlease type 'Yes' or 'No'.\")\n",
    "\n",
    "        if custom == 'Yes':\n",
    "            #get input to ask for the Title, X-axis label, and Y-axis label\n",
    "            title = input(\"Please enter a title for the plot: \")\n",
    "            x_label = input(\"Please enter a label for the x-axis: \")\n",
    "            y_label = input(\"Please enter a label for the y-axis: \")\n",
    "        \n",
    "        else:\n",
    "            #set the title, x-axis label, and y-axis label to default values\n",
    "            title = \"Histogram of Ratings\"\n",
    "            x_label = \"Rating\"\n",
    "            y_label = \"Frequency\"\n",
    "\n",
    "        #histogram for 1 through 5 star ratings\n",
    "        plt.hist(self.data['stars'], bins = 5)\n",
    "        plt.title(title)\n",
    "        plt.xlabel(x_label)\n",
    "        plt.ylabel(y_label)\n",
    "\n",
    "        #save the plot\n",
    "        plt.savefig(path)\n",
    "        #close the plot\n",
    "        plt.close()\n",
    "\n",
    "        #plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#use inheritance to create QuantDataSet class\n",
    "class QuantDataSet(DataSet):\n",
    "    \"\"\"\n",
    "    Class for managing the quantitative dataset. \n",
    "    \"\"\"\n",
    "\n",
    "    #constructor\n",
    "    def __init__(self, filename):\n",
    "        \"\"\"\n",
    "        Initializes the QuantDataSet class\n",
    "        \"\"\"\n",
    "        super().__init__(filename)\n",
    "        self.filename = filename\n",
    "        self.data = self._DataSet__load(filename)\n",
    "\n",
    "    #override the clean and explore methods from the DataSet class to be specific to the QuantDataSet class\n",
    "    def clean(self, header = True):\n",
    "        \"\"\"\n",
    "        Cleans the quantitative data set. Replaces missing values with the mean.\n",
    "\n",
    "        Args:\n",
    "            header (bool): whether or not the file has a header\n",
    "\n",
    "        Returns:\n",
    "            cleaned_data (np.array): the cleaned data\n",
    "        \"\"\"\n",
    "        try: \n",
    "            if self.data is None:\n",
    "                self._DataSet__load(self.filename)\n",
    "\n",
    "            print(\"Cleaning Quant Data Set...\")\n",
    "\n",
    "            #iterate by column replacing missing values with the mean\n",
    "            for col_name in self.data.dtype.names:\n",
    "                col_data = self.data[col_name]\n",
    "\n",
    "                #if the data is numeric\n",
    "                if np.issubdtype(col_data.dtype, np.number):\n",
    "                    #replace missing values with the mean limited to 2 decimal places\n",
    "                    col_data[np.isnan(col_data)] = np.round(np.nanmean(col_data), 2)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error cleaning {self.filename}: {str(e)}\")\n",
    "\n",
    "    def explore(self):\n",
    "        \"\"\"\n",
    "        Explores the quantitative data set. Creates a bar plot of the normalized sales for a given product and a bar plot of the total sales for each week. The user has the option of specifying a title, x-axis label, and y-axis label for the plot.\n",
    "        \"\"\"\n",
    "        print(\"Exploring Quant Data Set...\")\n",
    "\n",
    "        #ask the user for a Product ID to visualize\n",
    "        product_id = input(\"Please enter a Product ID to visualize: \")\n",
    "\n",
    "        i = 0\n",
    "        for row in self.data:\n",
    "            if row['Product_Code'] == product_id:\n",
    "                row_indx = i \n",
    "            i += 1\n",
    "\n",
    "\n",
    "        data_names = []\n",
    "        for i in range(0, 52):\n",
    "            data_names.append(f'Normalized {i}')\n",
    "\n",
    "        vals = []\n",
    "\n",
    "        for name in data_names:\n",
    "            vals.append(self.data[row_indx][name])\n",
    "\n",
    "        #create a bar plot using vals with the data_names as the x-axis labels and the title, x-axis label, and y-axis label as specified by the user if they want\n",
    "        custom = input(\"Would you like to specify the title, x-axis label, and y-axis label for the bar plot? \\nPlease type 'Yes' or 'No'.\")\n",
    "        if custom == 'Yes':\n",
    "            #get input to ask for the Title, X-axis label, and Y-axis label\n",
    "            title = input(\"Please enter a title for the plot: \")\n",
    "            x_label = input(\"Please enter a label for the x-axis: \")\n",
    "            y_label = input(\"Please enter a label for the y-axis: \")\n",
    "\n",
    "        else:\n",
    "            #set the title, x-axis label, and y-axis label to default values\n",
    "            title = (f\"Normalized Sales | Product ID: {product_id}\")\n",
    "            x_label = \"Week\"\n",
    "            y_label = \"Normalized Sales\"\n",
    "\n",
    "        path = f'visualizations/Normalized_Sales_{product_id}.png'\n",
    "\n",
    "        plt.figsize=(10, 6)\n",
    "\n",
    "        plt.bar(data_names, vals)\n",
    "        plt.title(title)\n",
    "        plt.xlabel(x_label)\n",
    "        plt.ylabel(y_label)\n",
    "        #get rid of x-axis labels because they are too long\n",
    "        plt.xticks([])\n",
    "\n",
    "        #save the plot\n",
    "        plt.savefig(path)\n",
    "        #close the plot\n",
    "        plt.close()\n",
    "\n",
    "        #plt.show()\n",
    "\n",
    "        #do the same for non-normalized sales\n",
    "        data_names = []\n",
    "        for i in range(0, 52):\n",
    "            data_names.append(f'W{i}')\n",
    "\n",
    "        #sum each product to get the total sales for each week\n",
    "        total_sales = []\n",
    "\n",
    "        for i in range(0, 52):\n",
    "            total_sales.append(np.sum(self.data[f'W{i}']))\n",
    "\n",
    "        #create a bar plot using vals with the data_names as the x-axis labels and the title, x-axis label, and y-axis label as specified by the user if they want\n",
    "        custom = input(\"Would you like to specify the title, x-axis label, and y-axis label for the bar plot? \\nPlease type 'Yes' or 'No'.\")\n",
    "        if custom == 'Yes':\n",
    "            #get input to ask for the Title, X-axis label, and Y-axis label\n",
    "            title = input(\"Please enter a title for the plot: \")\n",
    "            x_label = input(\"Please enter a label for the x-axis: \")\n",
    "            y_label = input(\"Please enter a label for the y-axis: \")\n",
    "        else:\n",
    "            #set the title, x-axis label, and y-axis label to default values\n",
    "            title = \"Total Sales | Every Product\"\n",
    "            x_label = \"Week\"\n",
    "            y_label = \"Total Sales\"\n",
    "\n",
    "        path = 'visualizations/Total_Sales.png'\n",
    "\n",
    "        plt.figsize=(10, 6)\n",
    "\n",
    "        plt.bar(data_names, total_sales)\n",
    "        plt.title(title)\n",
    "        plt.xlabel(x_label)\n",
    "        plt.ylabel(y_label)\n",
    "        #get rid of x-axis labels because they are too long\n",
    "        plt.xticks([])\n",
    "\n",
    "        #save the plot\n",
    "        plt.savefig(path)\n",
    "        #close the plot\n",
    "        plt.close()\n",
    "\n",
    "        #plt.show()\n",
    "        \n",
    "\n",
    "\n",
    "#use inheritance to create QualDataSet class\n",
    "class QualDataSet(DataSet):\n",
    "    \"\"\"\n",
    "    Class for managing the qualitative dataset. \n",
    "    \"\"\"\n",
    "\n",
    "    #constructor\n",
    "    def __init__(self, filename):\n",
    "        \"\"\"\n",
    "        Initializes the QualDataSet class\n",
    "        \"\"\"\n",
    "        super().__init__(filename)\n",
    "        self.filename = filename\n",
    "        self.data = self._DataSet__load(filename)\n",
    "\n",
    "    #override the clean and explore methods from the DataSet class to be specific to the QualDataSet class\n",
    "    def clean(self):\n",
    "        \"\"\" \n",
    "        Cleans the qualitative data set, replacing missing values in numeric columns with the median and replacing missing values in string columns with the mode. There are a lot of nan values towards the end of the data, I'm not sure if this was how it was intended in the prompt, but I still consider nan a value. So if nan is the most common response empty values will be replaced with nan. Some questions have very few responses. \n",
    "\n",
    "        Returns:\n",
    "            cleaned_data (np.array): the cleaned data\n",
    "        \"\"\"\n",
    "        print(\"Cleaning Qual Data Set...\")\n",
    "\n",
    "        try:\n",
    "            for col_name in self.data.dtype.names:\n",
    "                col_data = self.data[col_name]\n",
    "\n",
    "                #if the data is numeric\n",
    "                if np.issubdtype(col_data.dtype, np.number):\n",
    "                    #replace missing values with the median limited to 2 decimal places\n",
    "                    col_data[np.isnan(col_data)] = np.round(np.nanmedian(col_data), 2)\n",
    "                else:\n",
    "                    #convert any np.nan to 'nan' so mode can be used\n",
    "                    col_data[col_data != col_data] = 'nan'\n",
    "                    #replace missing values with the mode\n",
    "                    mode = max(set(col_data), key = list(col_data).count)\n",
    "                    col_data[col_data == 'nan'] = mode\n",
    "                \n",
    "                self.data[col_name] = col_data\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error cleaning {self.filename}: {str(e)}\")\n",
    "\n",
    "        try: \n",
    "            self.data = self.data[1:]\n",
    "        except Exception as e:\n",
    "            print(f\"Error cleaning {self.filename}, header error: {str(e)}\")\n",
    "        \n",
    "\n",
    "                    \n",
    "    def explore(self):\n",
    "        \"\"\"\n",
    "        Explores the qualitative data set. The user has the option of specifying a title, x-axis label, and y-axis label for the plot. Creates a bar plot of the degrees of the respondents and a bar plot of the first recommended programming language for data science.\n",
    "        \"\"\"\n",
    "        print(\"Exploring Qual Data Set...\")\n",
    "\n",
    "        #get unique degree from Q4\n",
    "        degrees = np.unique(self.data['Q4'])\n",
    "\n",
    "        #get the counts for each degree\n",
    "        counts = []\n",
    "\n",
    "        for degree in degrees:\n",
    "            counts.append(np.sum(self.data['Q4'] == degree))\n",
    "\n",
    "        #create a bar plot using counts with the degrees as the x-axis labels and the title, x-axis label, and y-axis label as specified by the user if they want\n",
    "        custom = input(\"Would you like to specify the title, x-axis label, and y-axis label for the bar plot? \\nPlease type 'Yes' or 'No'.\")\n",
    "        if custom == 'Yes':\n",
    "            title = input(\"Please enter a title for the plot: \")\n",
    "            x_label = input(\"Please enter a label for the x-axis: \")\n",
    "            y_label = input(\"Please enter a label for the y-axis: \")\n",
    "        else:\n",
    "            #set the title, x-axis label, and y-axis label to default values\n",
    "            title = \"Degrees\"\n",
    "            x_label = \"Degree\"\n",
    "            y_label = \"Frequency\"\n",
    "\n",
    "        #creating labels so the x-axis is not so cluttered\n",
    "        val_labels = {\n",
    "            \"Doctoral degree\": \"Doctoral\",\n",
    "            \"Master’s degree\": \"Master’s\",\n",
    "            \"Bachelor’s degree\": \"Bachelor’s\",\n",
    "            \"Some college/university study without earning a bachelor’s degree\": \"Some College\",\n",
    "            \"Professional degree\": \"Professional\",\n",
    "            \"No formal education past high school\": \"High-School\",\n",
    "            \"I prefer not to answer\": \"No Answer\",\n",
    "        }\n",
    "\n",
    "        x_label_list = [val_labels[degree] for degree in degrees]\n",
    "\n",
    "        path = 'visualizations/Degrees.png'\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "\n",
    "        plt.bar(x_label_list, counts)\n",
    "        plt.title(title)\n",
    "        plt.xlabel(x_label)\n",
    "        plt.ylabel(y_label)\n",
    "        #fix x ticks and rotate them to 60 degrees\n",
    "        plt.xticks(rotation = 45)\n",
    "        #plt.show()\n",
    "\n",
    "        #save the plot\n",
    "        plt.savefig(path)\n",
    "        #close the plot\n",
    "        plt.close()\n",
    "\n",
    "        #now I want to see what programming languages are recommended, \n",
    "        #creating a histogram of Q19\n",
    "        languages = np.unique(self.data['Q19'])\n",
    "\n",
    "        #get the counts for each language\n",
    "        counts = []\n",
    "\n",
    "        for language in languages:\n",
    "            counts.append(np.sum(self.data['Q19'] == language))\n",
    "\n",
    "        #create a bar plot using counts with the languages as the x-axis labels and the title, x-axis label, and y-axis label as specified by the user if they want\n",
    "        custom = input(\"Would you like to specify the title, x-axis label, and y-axis label for the bar plot? \\nPlease type 'Yes' or 'No'.\")\n",
    "        if custom == 'Yes':\n",
    "            title = input(\"Please enter a title for the plot: \")\n",
    "            x_label = input(\"Please enter a label for the x-axis: \")\n",
    "            y_label = input(\"Please enter a label for the y-axis: \")\n",
    "        else:\n",
    "            title = \"First Recommended Programming Language for Data Science\"\n",
    "            x_label = \"Language\"\n",
    "            y_label = \"Frequency\"\n",
    "\n",
    "        path = 'visualizations/First_Recommended_Language.png'\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "\n",
    "        plt.bar(languages, counts)\n",
    "        plt.title(title)\n",
    "        plt.xlabel(x_label)\n",
    "        plt.ylabel(y_label)\n",
    "        #fix x ticks and rotate them to 60 degrees\n",
    "        plt.xticks(rotation = 45)\n",
    "\n",
    "        #save the plot\n",
    "        plt.savefig(path)\n",
    "        #close the plot\n",
    "        plt.close()\n",
    "\n",
    "        #plt.show()\n",
    "        \n",
    "\n",
    "#create class for the classifier \n",
    "class ClassifierAlgotithm:\n",
    "    \"\"\"\n",
    "    Class for managing the classifier algorithm\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the ClassifierAlgotithm class\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def train(self, train_data, train_labels):\n",
    "        \"\"\"\n",
    "        Trains the classifier algorithm\n",
    "        \"\"\"\n",
    "        print(\"Training...\")\n",
    "\n",
    "    def test(self, test_data, test_labels):\n",
    "        \"\"\"\n",
    "        Tests the classifier algorithm\n",
    "        \"\"\"\n",
    "        print(\"Testing...\")\n",
    "\n",
    "#create class for simpe KNN that inherets from ClassifierAlgotithm\n",
    "class simpleKNNClassifier(ClassifierAlgotithm):\n",
    "    \"\"\"\n",
    "    Class for managing the simple KNN classifier\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the simpleKNNClassifier class\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.data = None\n",
    "        self.labels = None\n",
    "        self.pred_labels = None\n",
    "\n",
    "    def train(self, train_data, train_labels):\n",
    "        \"\"\"\n",
    "        Trains the simple KNN classifier\n",
    "\n",
    "        Args:\n",
    "            train_data (np.array): the training data\n",
    "            train_labels (np.array): the training labels\n",
    "        \"\"\"\n",
    "        print(\"Training simple KNN...\")\n",
    "\n",
    "        self.data = train_data\n",
    "        self.labels = train_labels\n",
    "\n",
    "    def test(self, test_data, k):\n",
    "        \"\"\"\n",
    "        Tests the simple KNN classifier\n",
    "        \"\"\"\n",
    "        preds = []\n",
    "\n",
    "        for test in test_data:\n",
    "            #get the distance from the test to each sample\n",
    "            samples = np.linalg.norm(self.data - test, axis=1)\n",
    "            #sort the samples and get indices of the k closest\n",
    "            sorted_samples = np.argsort(samples)[:k]\n",
    "\n",
    "            counts = {}\n",
    "            #count the number of times each label appears\n",
    "            for i in sorted_samples:\n",
    "                label = self.labels[i]\n",
    "                if label in counts:\n",
    "                    counts[label] += 1\n",
    "                else:\n",
    "                    counts[label] = 1\n",
    "\n",
    "            #get the most common label\n",
    "            mode = max(counts, key = counts.get)\n",
    "            preds.append(mode)\n",
    "\n",
    "        self.pred_labels = np.array(preds)\n",
    "        return preds\n",
    "\n",
    "\n",
    "\n",
    "#create class for kdTree KNN that inherets from ClassifierAlgotithm\n",
    "class kdTreeKNNClassifier(ClassifierAlgotithm):\n",
    "    \"\"\"\n",
    "    Class for managing the kdTree KNN classifier\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "#create the Experiment class that will run cross validation, get a score given k and, and create a confusion matrix\n",
    "class Experiment:\n",
    "    \"\"\"\n",
    "    Class for managing the experiment\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the Experiment class\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def runCrossVal(self, k):\n",
    "        \"\"\"\n",
    "        Runs k-fold cross validation\n",
    "\n",
    "        Args:\n",
    "            k (int): the number of folds to use\n",
    "        \"\"\"\n",
    "        print(f\"Running {k}-fold cross validation...\")\n",
    "\n",
    "    def score(self):\n",
    "        \"\"\"\n",
    "        Scores the experiment\n",
    "        \"\"\"\n",
    "        print(\"Scoring...\")\n",
    "\n",
    "    def __confusionMatrix(self):\n",
    "        \"\"\"\n",
    "        Creates a confusion matrix\n",
    "        \"\"\"\n",
    "        print(\"Creating confusion matrix...\")\n",
    "\n",
    "\n",
    "#I have created a bash script to ruan all of this automatically so the grader doesn't have to give input for each of the data sets could be annoying when grading multple people's projects\n",
    "\n",
    "#cleaned data and visualizations are saved to the cleaned_data and visualizations folders respectively\n",
    "\n",
    "#data is pulled from the data folder\n",
    "\n",
    "#all paths are refrenced locally\n",
    "\n",
    "#create a main function to test all of my updates\n",
    "if __name__ == \"__main__\":\n",
    "    paths = {\n",
    "        'time': 'data/Time_ECG.csv',\n",
    "        'text': 'data/Text_Yelp.csv',\n",
    "        'quant': 'data/Quant_Sales.csv',\n",
    "        'qual': 'data/Qual_Survey.csv'\n",
    "    }\n",
    "\n",
    "    #create a folder called cleaned_data to store the cleaned data from each of the data sets\n",
    "    try:\n",
    "        os.mkdir('cleaned_data')\n",
    "    except:\n",
    "        print(\"Couldnt make cleaned_data folder or it already exists\")\n",
    "\n",
    "    #create a folder called visualizations to store the visualizations from each of the data sets\n",
    "    try:\n",
    "        os.mkdir('visualizations')\n",
    "    except:\n",
    "        print(\"Couldnt make visualizations folder or it already exists\")\n",
    "\n",
    "    print(\"---Starting Test---\")\n",
    "    print(\"Testing Time Series Data Set...\")\n",
    "    time_data = TimeSeriesDataSet(paths['time'])\n",
    "    time_data.clean()\n",
    "    np.savetxt('cleaned_data/cleaned_time_data.csv', time_data.data, delimiter=',', fmt='%s')\n",
    "    print(\"First row of cleaned data: \")\n",
    "    print(time_data.data[:1])\n",
    "    time_data.explore()\n",
    "\n",
    "    print('\\n')\n",
    "    print(\"Testing Text Data Set...\")\n",
    "    text_data = TextDataSet(paths['text'])\n",
    "    text_data.clean()\n",
    "    np.savetxt('cleaned_data/cleaned_text_data.csv', text_data.data, delimiter=',', fmt='%s')\n",
    "    print(\"First row of cleaned data: \")\n",
    "    print(text_data.data[:1])\n",
    "    text_data.explore()\n",
    "\n",
    "    print('\\n')\n",
    "    print(\"Testing Quantitative Data Set...\")\n",
    "    quant_data = QuantDataSet(paths['quant'])\n",
    "    quant_data.clean()\n",
    "    np.savetxt('cleaned_data/cleaned_quant_data.csv', quant_data.data, delimiter=',', fmt='%s')\n",
    "    print(\"First 1 row of cleaned data: \")\n",
    "    print(quant_data.data[:1])\n",
    "    quant_data.explore()\n",
    "\n",
    "    print('\\n')\n",
    "    print(\"Testing Qualitative Data Set...\")\n",
    "    qual_data = QualDataSet(paths['qual'])\n",
    "    qual_data.clean()\n",
    "    np.savetxt('cleaned_data/cleaned_qual_data.csv', qual_data.data, delimiter=',', fmt='%s')\n",
    "    print(\"Firs row of cleaned data: \")\n",
    "    print(qual_data.data[:1])\n",
    "    qual_data.explore()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
